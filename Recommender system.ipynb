{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import packages and dataset"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ndata = pd.read_csv('books.csv')\ndata.head()","execution_count":1,"outputs":[{"output_type":"execute_result","execution_count":1,"data":{"text/plain":"   id  book_id  best_book_id  work_id  books_count       isbn        isbn13  \\\n0   1  2767052       2767052  2792775          272  439023483  9.780439e+12   \n1   2        3             3  4640799          491  439554934  9.780440e+12   \n2   3    41865         41865  3212258          226  316015849  9.780316e+12   \n3   4     2657          2657  3275794          487   61120081  9.780061e+12   \n4   5     4671          4671   245494         1356  743273567  9.780743e+12   \n\n                       authors  original_publication_year  \\\n0              Suzanne Collins                     2008.0   \n1  J.K. Rowling, Mary GrandPré                     1997.0   \n2              Stephenie Meyer                     2005.0   \n3                   Harper Lee                     1960.0   \n4          F. Scott Fitzgerald                     1925.0   \n\n                             original_title  ... ratings_count  \\\n0                          The Hunger Games  ...       4780653   \n1  Harry Potter and the Philosopher's Stone  ...       4602479   \n2                                  Twilight  ...       3866839   \n3                     To Kill a Mockingbird  ...       3198671   \n4                          The Great Gatsby  ...       2683664   \n\n  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n0            4942365                   155254      66715     127936   \n1            4800065                    75867      75504     101676   \n2            3916824                    95009     456191     436802   \n3            3340896                    72586      60427     117415   \n4            2773745                    51992      86236     197621   \n\n   ratings_3  ratings_4  ratings_5  \\\n0     560092    1481305    2706317   \n1     455024    1156318    3011543   \n2     793319     875073    1355439   \n3     446835    1001952    1714267   \n4     606158     936012     947718   \n\n                                           image_url  \\\n0  https://images.gr-assets.com/books/1447303603m...   \n1  https://images.gr-assets.com/books/1474154022m...   \n2  https://images.gr-assets.com/books/1361039443m...   \n3  https://images.gr-assets.com/books/1361975680m...   \n4  https://images.gr-assets.com/books/1490528560m...   \n\n                                     small_image_url  \n0  https://images.gr-assets.com/books/1447303603s...  \n1  https://images.gr-assets.com/books/1474154022s...  \n2  https://images.gr-assets.com/books/1361039443s...  \n3  https://images.gr-assets.com/books/1361975680s...  \n4  https://images.gr-assets.com/books/1490528560s...  \n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>book_id</th>\n      <th>best_book_id</th>\n      <th>work_id</th>\n      <th>books_count</th>\n      <th>isbn</th>\n      <th>isbn13</th>\n      <th>authors</th>\n      <th>original_publication_year</th>\n      <th>original_title</th>\n      <th>...</th>\n      <th>ratings_count</th>\n      <th>work_ratings_count</th>\n      <th>work_text_reviews_count</th>\n      <th>ratings_1</th>\n      <th>ratings_2</th>\n      <th>ratings_3</th>\n      <th>ratings_4</th>\n      <th>ratings_5</th>\n      <th>image_url</th>\n      <th>small_image_url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2767052</td>\n      <td>2767052</td>\n      <td>2792775</td>\n      <td>272</td>\n      <td>439023483</td>\n      <td>9.780439e+12</td>\n      <td>Suzanne Collins</td>\n      <td>2008.0</td>\n      <td>The Hunger Games</td>\n      <td>...</td>\n      <td>4780653</td>\n      <td>4942365</td>\n      <td>155254</td>\n      <td>66715</td>\n      <td>127936</td>\n      <td>560092</td>\n      <td>1481305</td>\n      <td>2706317</td>\n      <td>https://images.gr-assets.com/books/1447303603m...</td>\n      <td>https://images.gr-assets.com/books/1447303603s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>3</td>\n      <td>3</td>\n      <td>4640799</td>\n      <td>491</td>\n      <td>439554934</td>\n      <td>9.780440e+12</td>\n      <td>J.K. Rowling, Mary GrandPré</td>\n      <td>1997.0</td>\n      <td>Harry Potter and the Philosopher's Stone</td>\n      <td>...</td>\n      <td>4602479</td>\n      <td>4800065</td>\n      <td>75867</td>\n      <td>75504</td>\n      <td>101676</td>\n      <td>455024</td>\n      <td>1156318</td>\n      <td>3011543</td>\n      <td>https://images.gr-assets.com/books/1474154022m...</td>\n      <td>https://images.gr-assets.com/books/1474154022s...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>41865</td>\n      <td>41865</td>\n      <td>3212258</td>\n      <td>226</td>\n      <td>316015849</td>\n      <td>9.780316e+12</td>\n      <td>Stephenie Meyer</td>\n      <td>2005.0</td>\n      <td>Twilight</td>\n      <td>...</td>\n      <td>3866839</td>\n      <td>3916824</td>\n      <td>95009</td>\n      <td>456191</td>\n      <td>436802</td>\n      <td>793319</td>\n      <td>875073</td>\n      <td>1355439</td>\n      <td>https://images.gr-assets.com/books/1361039443m...</td>\n      <td>https://images.gr-assets.com/books/1361039443s...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>2657</td>\n      <td>2657</td>\n      <td>3275794</td>\n      <td>487</td>\n      <td>61120081</td>\n      <td>9.780061e+12</td>\n      <td>Harper Lee</td>\n      <td>1960.0</td>\n      <td>To Kill a Mockingbird</td>\n      <td>...</td>\n      <td>3198671</td>\n      <td>3340896</td>\n      <td>72586</td>\n      <td>60427</td>\n      <td>117415</td>\n      <td>446835</td>\n      <td>1001952</td>\n      <td>1714267</td>\n      <td>https://images.gr-assets.com/books/1361975680m...</td>\n      <td>https://images.gr-assets.com/books/1361975680s...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>4671</td>\n      <td>4671</td>\n      <td>245494</td>\n      <td>1356</td>\n      <td>743273567</td>\n      <td>9.780743e+12</td>\n      <td>F. Scott Fitzgerald</td>\n      <td>1925.0</td>\n      <td>The Great Gatsby</td>\n      <td>...</td>\n      <td>2683664</td>\n      <td>2773745</td>\n      <td>51992</td>\n      <td>86236</td>\n      <td>197621</td>\n      <td>606158</td>\n      <td>936012</td>\n      <td>947718</td>\n      <td>https://images.gr-assets.com/books/1490528560m...</td>\n      <td>https://images.gr-assets.com/books/1490528560s...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"Index(['id', 'book_id', 'best_book_id', 'work_id', 'books_count', 'isbn',\n       'isbn13', 'authors', 'original_publication_year', 'original_title',\n       'title', 'language_code', 'average_rating', 'ratings_count',\n       'work_ratings_count', 'work_text_reviews_count', 'ratings_1',\n       'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5', 'image_url',\n       'small_image_url'],\n      dtype='object')"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"id                              0\nbook_id                         0\nbest_book_id                    0\nwork_id                         0\nbooks_count                     0\nisbn                          700\nisbn13                        585\nauthors                         0\noriginal_publication_year      21\noriginal_title                585\ntitle                           0\nlanguage_code                1084\naverage_rating                  0\nratings_count                   0\nwork_ratings_count              0\nwork_text_reviews_count         0\nratings_1                       0\nratings_2                       0\nratings_3                       0\nratings_4                       0\nratings_5                       0\nimage_url                       0\nsmall_image_url                 0\ndtype: int64"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Pre processing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Extract relevant columns that would influence a book's rating based on book title. \nbooks_title = data[['book_id', 'title']]\nbooks_title.head()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"   book_id                                              title\n0  2767052            The Hunger Games (The Hunger Games, #1)\n1        3  Harry Potter and the Sorcerer's Stone (Harry P...\n2    41865                            Twilight (Twilight, #1)\n3     2657                              To Kill a Mockingbird\n4     4671                                   The Great Gatsby","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book_id</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2767052</td>\n      <td>The Hunger Games (The Hunger Games, #1)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41865</td>\n      <td>Twilight (Twilight, #1)</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2657</td>\n      <td>To Kill a Mockingbird</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4671</td>\n      <td>The Great Gatsby</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Recommender"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets vectorize all these titles\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n#initialize vectorizer\nvect = CountVectorizer(analyzer = 'word', ngram_range = (1,2), stop_words = 'english', min_df = 0.002) #min_df = rare words, max_df = most used words\n#ngram_range = (1,2) - if used more than  1(value), lots of features or noise\n\n#Fit into the title\nvect.fit(books_title['title'])\ntitle_matrix = vect.transform(books_title['title'])\ntitle_matrix.shape","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"(10000, 261)"},"metadata":{}}]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#Lets find vocabulary/features\nfeatures = vect.get_feature_names()\nfeatures","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"['01',\n '10',\n '11',\n '12',\n '13',\n '14',\n '15',\n '16',\n '39',\n 'adventures',\n 'alex',\n 'alex cross',\n 'america',\n 'american',\n 'angel',\n 'angels',\n 'anita',\n 'anita blake',\n 'apprentice',\n 'art',\n 'bad',\n 'batman',\n 'beautiful',\n 'beauty',\n 'best',\n 'big',\n 'black',\n 'blake',\n 'blake vampire',\n 'blood',\n 'blue',\n 'body',\n 'bone',\n 'bones',\n 'book',\n 'books',\n 'born',\n 'bosch',\n 'bosch universe',\n 'boy',\n 'boys',\n 'broken',\n 'brothers',\n 'case',\n 'cat',\n 'child',\n 'children',\n 'chronicles',\n 'circle',\n 'city',\n 'club',\n 'complete',\n 'confessions',\n 'cross',\n 'cycle',\n 'dance',\n 'dark',\n 'dark hunter',\n 'darkest',\n 'darkness',\n 'daughter',\n 'davenport',\n 'dawn',\n 'day',\n 'days',\n 'dead',\n 'death',\n 'death death',\n 'detective',\n 'devil',\n 'diaries',\n 'diary',\n 'die',\n 'discworld',\n 'dog',\n 'don',\n 'dragon',\n 'dream',\n 'dreams',\n 'earth',\n 'empire',\n 'end',\n 'fall',\n 'fallen',\n 'family',\n 'fear',\n 'files',\n 'food',\n 'forever',\n 'forgotten',\n 'forgotten realms',\n 'game',\n 'garden',\n 'girl',\n 'girls',\n 'glass',\n 'god',\n 'gods',\n 'golden',\n 'gone',\n 'good',\n 'grave',\n 'great',\n 'green',\n 'guide',\n 'hard',\n 'harry',\n 'harry bosch',\n 'harry potter',\n 'heart',\n 'heaven',\n 'hercule',\n 'hercule poirot',\n 'hidden',\n 'high',\n 'history',\n 'home',\n 'house',\n 'human',\n 'hunter',\n 'ice',\n 'immortals',\n 'inside',\n 'island',\n 'jack',\n 'jack reacher',\n 'john',\n 'journey',\n 'just',\n 'kay',\n 'kay scarpetta',\n 'key',\n 'king',\n 'kinsey',\n 'kinsey millhone',\n 'kiss',\n 'knight',\n 'know',\n 'lady',\n 'left',\n 'legacy',\n 'legend',\n 'life',\n 'light',\n 'like',\n 'little',\n 'lives',\n 'living',\n 'long',\n 'lord',\n 'lost',\n 'love',\n 'lucas',\n 'lucas davenport',\n 'magic',\n 'magician',\n 'man',\n 'memoir',\n 'men',\n 'mercy',\n 'midnight',\n 'millhone',\n 'mind',\n 'miss',\n 'moon',\n 'mr',\n 'murder',\n 'new',\n 'night',\n 'novel',\n 'novels',\n 'old',\n 'people',\n 'perfect',\n 'plum',\n 'poems',\n 'poirot',\n 'potter',\n 'power',\n 'pretty',\n 'prey',\n 'prey lucas',\n 'prince',\n 'princess',\n 'queen',\n 'reacher',\n 'realms',\n 'red',\n 'rising',\n 'river',\n 'road',\n 'rock',\n 'rose',\n 'saga',\n 'scarpetta',\n 'school',\n 'science',\n 'sea',\n 'second',\n 'secret',\n 'secrets',\n 'series',\n 'set',\n 'seven',\n 'shadow',\n 'shadows',\n 'short',\n 'sisters',\n 'small',\n 'snow',\n 'son',\n 'song',\n 'soul',\n 'star',\n 'stars',\n 'stephanie',\n 'stephanie plum',\n 'stone',\n 'stories',\n 'storm',\n 'story',\n 'strange',\n 'street',\n 'summer',\n 'sun',\n 'sword',\n 'tale',\n 'tales',\n 'tell',\n 'things',\n 'time',\n 'tree',\n 'trilogy',\n 'true',\n 'true story',\n 'truth',\n 'twilight',\n 'universe',\n 'vampire',\n 'vampire hunter',\n 'vampires',\n 'vol',\n 'volume',\n 'walking',\n 'walking dead',\n 'war',\n 'wars',\n 'water',\n 'way',\n 'wheel',\n 'white',\n 'wicked',\n 'wife',\n 'wild',\n 'winter',\n 'witch',\n 'woman',\n 'women',\n 'world',\n 'year',\n 'years']"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Cosine Similarity between Titles"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\ncosine_sim_titles = cosine_similarity(title_matrix, title_matrix)\ncosine_sim_titles.shape","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"(10000, 10000)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get books which are similar to a given title\ntitle_id = 100\nbooks_title['title'].iloc[title_id]","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"'Me Talk Pretty One Day'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Find out what features have been considered  by the vectorizer for a given title ?\nfeature_array = np.squeeze(title_matrix[title_id].toarray()) #squeeze activity matrix into array\nidx = np.where(feature_array > 0)\nidx[0]\n[features[x] for x in idx[0]]","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"['day', 'pretty']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find index of feature\nidx[0]","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"array([ 63, 179])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cosine similarity with other similar titles\nn = 15 #how many books to be recommended\ntop_n_idx = np.flip(np.argsort(cosine_sim_titles[title_id,]), axis = 0)[0:n]\ntop_n_sim_values = cosine_sim_titles[title_id, top_n_idx]\ntop_n_sim_values","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"array([1.        , 0.70710678, 0.70710678, 0.70710678, 0.70710678,\n       0.70710678, 0.70710678, 0.70710678, 0.70710678, 0.70710678,\n       0.70710678, 0.70710678, 0.70710678, 0.70710678, 0.70710678])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#find top n with values > 0\ntop_n_idx = top_n_idx[top_n_sim_values > 0]\n#Matching books\nbooks_title['title'].iloc[top_n_idx]","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"100                                Me Talk Pretty One Day\n3729                                            Labor Day\n988                                 The Day of the Jackal\n836                             Every Day (Every Day, #1)\n2348    No Easy Day: The Firsthand Account of the Miss...\n3311                                          Pretty Baby\n6804                     Graduation Day (The Testing, #3)\n6886                                 Day Watch (Watch #2)\n5765                          The Given Day (Coughlin #1)\n783                                      For One More Day\n9210             Beyond Exile (Day by Day Armageddon,# 2)\n9703    The Pretty Committee Strikes Back (The Clique,...\n9637                                 Day 21 (The 100, #2)\n7330                                      Pretty in Plaid\n7707                            A Grown-Up Kind of Pretty\nName: title, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets wrap the above code in a function\ndef return_sim_books(title_id, title_matrix, vectorizer, top_n = 10):\n    \n    # generate sim matrix\n    sim_matrix = cosine_similarity(title_matrix, title_matrix)\n    features = vectorizer.get_feature_names()\n\n    top_n_idx = np.flip(np.argsort(sim_matrix[title_id,]),axis=0)[0:top_n]\n    top_n_sim_values = sim_matrix[title_id, top_n_idx]\n    \n    # find top n with values > 0\n    top_n_idx = top_n_idx[top_n_sim_values > 0]\n    scores = top_n_sim_values[top_n_sim_values > 0]\n    \n    \n    # find features from the vectorized matrix\n    sim_books_idx = books_title['title'].iloc[top_n_idx].index\n    words = []\n    for book_idx in sim_books_idx:\n        try:\n            feature_array = np.squeeze(title_matrix[book_idx,].toarray())\n        except:\n            feature_array = np.squeeze(title_matrix[book_idx,])\n        idx = np.where(feature_array > 0)\n        words.append([\" , \".join([features[i] for i in idx[0]])])\n        \n    # collate results\n    res = pd.DataFrame({\"book_title\" : books_title['title'].iloc[title_id],\n           \"sim_books\": books_title['title'].iloc[top_n_idx].values,\"words\":words,\n           \"scores\":scores}, columns = [\"book_title\",\"sim_books\",\"scores\",\"words\"])\n    \n    \n    return res","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vect = CountVectorizer(analyzer='word',ngram_range=(1,2),stop_words='english', min_df = 0.001)\nvect.fit(books_title['title'])\ntitle_matrix = vect.transform(books_title['title'])\nprint(books_title['title'][10])\nreturn_sim_books(10,title_matrix,vect,top_n=10)","execution_count":14,"outputs":[{"output_type":"stream","text":"The Kite Runner\n","name":"stdout"},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"Empty DataFrame\nColumns: [book_title, sim_books, scores, words]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book_title</th>\n      <th>sim_books</th>\n      <th>scores</th>\n      <th>words</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"\n\n# Using Tf-Idf Vectorizer\n","attachments":{}},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import linear_kernel\n\ntf = TfidfVectorizer(analyzer = 'word', ngram_range = (1,2), min_df = 0, stop_words = 'english')\ntfidf_matrix = tf.fit_transform(books_title['title'])\ncosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\ncosine_sim","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"array([[1., 0., 0., ..., 0., 0., 0.],\n       [0., 1., 0., ..., 0., 0., 0.],\n       [0., 0., 1., ..., 0., 0., 0.],\n       ...,\n       [0., 0., 0., ..., 1., 0., 0.],\n       [0., 0., 0., ..., 0., 1., 0.],\n       [0., 0., 0., ..., 0., 0., 1.]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"titles = books_title['title']\nindices = pd.Series(books_title.index, index = books_title['title']) #converting all titles into a Series\n\n#Function that gets book recommendations based on the cosine similarity score of book titles\ndef book_recommendations(title, n):\n    idx = indices[title]\n    sim_scores = list(enumerate(cosine_sim[idx]))\n    sim_scores = sorted(sim_scores, key = lambda x:x[1], reverse = True)\n    sim_scores = sim_scores[1:n+1]\n    book_indices = [i[0] for i in sim_scores]\n    return titles.iloc[book_indices]","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Recommend n books for a book having index 1\nbook_index = 10\nn = 20\n\nprint(books_title['title'][book_index])\nbook_recommendations(books_title.title[book_index],n)","execution_count":17,"outputs":[{"output_type":"stream","text":"The Kite Runner\n","name":"stdout"},{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"8946                                        Once a Runner\n90                      The Maze Runner (Maze Runner, #1)\n375                      The Death Cure (Maze Runner, #3)\n945                    The Kill Order (Maze Runner, #0.5)\n258                   The Scorch Trials (Maze Runner, #2)\n6711    Ultramarathon Man: Confessions of an All-Night...\n0                 The Hunger Games (The Hunger Games, #1)\n1       Harry Potter and the Sorcerer's Stone (Harry P...\n2                                 Twilight (Twilight, #1)\n3                                   To Kill a Mockingbird\n4                                        The Great Gatsby\n5                                  The Fault in Our Stars\n6                                              The Hobbit\n7                                  The Catcher in the Rye\n8                   Angels & Demons  (Robert Langdon, #1)\n9                                     Pride and Prejudice\n11                              Divergent (Divergent, #1)\n12                                                   1984\n13                                            Animal Farm\n14                              The Diary of a Young Girl\nName: title, dtype: object"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Recommend similar books based on a list of books read\n\nInput list of books"},{"metadata":{"trusted":true},"cell_type":"code","source":"book_recommendations('A Tale of Two Cities',3)","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"5871    A Tale of Two Cities / Great Expectations\n2697                             Invisible Cities\n1699                    A Tale for the Time Being\nName: title, dtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_list = pd.read_csv('books_read.csv')\nmy_list","execution_count":19,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] File ../input/books-read/books_read.csv does not exist: '../input/books-read/books_read.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-1fdb0d33b84e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmy_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/books-read/books_read.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmy_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File ../input/books-read/books_read.csv does not exist: '../input/books-read/books_read.csv'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame()\nn = 3 #Recommend top n similar books\nprint('Recommended books: ')\nfor i in my_list['Books read']:\n    output = pd.DataFrame(book_recommendations(i,n))\n    result = result.append(output)\nresult = result.drop_duplicates()\nresult","execution_count":20,"outputs":[{"output_type":"stream","text":"Recommended books: \n","name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"name 'my_list' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-37c721203370>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;31m#Recommend top n similar books\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Recommended books: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmy_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Books read'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbook_recommendations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'my_list' is not defined"]}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}