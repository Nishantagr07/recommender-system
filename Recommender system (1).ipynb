{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 55, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9c3d01043160>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\ML projects\\BX-Books.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1131\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2035\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2036\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2037\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2038\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 55, saw 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv(r'D:\\ML projects\\BX-Books.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'book_id', 'best_book_id', 'work_id', 'books_count', 'isbn',\n",
       "       'isbn13', 'authors', 'original_publication_year', 'original_title',\n",
       "       'title', 'language_code', 'average_rating', 'ratings_count',\n",
       "       'work_ratings_count', 'work_text_reviews_count', 'ratings_1',\n",
       "       'ratings_2', 'ratings_3', 'ratings_4', 'ratings_5', 'image_url',\n",
       "       'small_image_url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                              0\n",
       "book_id                         0\n",
       "best_book_id                    0\n",
       "work_id                         0\n",
       "books_count                     0\n",
       "isbn                          700\n",
       "isbn13                        585\n",
       "authors                         0\n",
       "original_publication_year      21\n",
       "original_title                585\n",
       "title                           0\n",
       "language_code                1084\n",
       "average_rating                  0\n",
       "ratings_count                   0\n",
       "work_ratings_count              0\n",
       "work_text_reviews_count         0\n",
       "ratings_1                       0\n",
       "ratings_2                       0\n",
       "ratings_3                       0\n",
       "ratings_4                       0\n",
       "ratings_5                       0\n",
       "image_url                       0\n",
       "small_image_url                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2767052</td>\n",
       "      <td>The Hunger Games (The Hunger Games, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41865</td>\n",
       "      <td>Twilight (Twilight, #1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2657</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4671</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id                                              title\n",
       "0  2767052            The Hunger Games (The Hunger Games, #1)\n",
       "1        3  Harry Potter and the Sorcerer's Stone (Harry P...\n",
       "2    41865                            Twilight (Twilight, #1)\n",
       "3     2657                              To Kill a Mockingbird\n",
       "4     4671                                   The Great Gatsby"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract relevant columns that would influence a book's rating based on book title. \n",
    "books_title = data[['book_id', 'title']]\n",
    "books_title.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 261)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets vectorize all these titles\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#initialize vectorizer\n",
    "vect = CountVectorizer(analyzer = 'word', ngram_range = (1,2), stop_words = 'english', min_df = 0.002) #min_df = rare words, max_df = most used words\n",
    "#ngram_range = (1,2) - if used more than  1(value), lots of features or noise\n",
    "\n",
    "#Fit into the title\n",
    "vect.fit(books_title['title'])\n",
    "title_matrix = vect.transform(books_title['title'])\n",
    "title_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '39',\n",
       " 'adventures',\n",
       " 'alex',\n",
       " 'alex cross',\n",
       " 'america',\n",
       " 'american',\n",
       " 'angel',\n",
       " 'angels',\n",
       " 'anita',\n",
       " 'anita blake',\n",
       " 'apprentice',\n",
       " 'art',\n",
       " 'bad',\n",
       " 'batman',\n",
       " 'beautiful',\n",
       " 'beauty',\n",
       " 'best',\n",
       " 'big',\n",
       " 'black',\n",
       " 'blake',\n",
       " 'blake vampire',\n",
       " 'blood',\n",
       " 'blue',\n",
       " 'body',\n",
       " 'bone',\n",
       " 'bones',\n",
       " 'book',\n",
       " 'books',\n",
       " 'born',\n",
       " 'bosch',\n",
       " 'bosch universe',\n",
       " 'boy',\n",
       " 'boys',\n",
       " 'broken',\n",
       " 'brothers',\n",
       " 'case',\n",
       " 'cat',\n",
       " 'child',\n",
       " 'children',\n",
       " 'chronicles',\n",
       " 'circle',\n",
       " 'city',\n",
       " 'club',\n",
       " 'complete',\n",
       " 'confessions',\n",
       " 'cross',\n",
       " 'cycle',\n",
       " 'dance',\n",
       " 'dark',\n",
       " 'dark hunter',\n",
       " 'darkest',\n",
       " 'darkness',\n",
       " 'daughter',\n",
       " 'davenport',\n",
       " 'dawn',\n",
       " 'day',\n",
       " 'days',\n",
       " 'dead',\n",
       " 'death',\n",
       " 'death death',\n",
       " 'detective',\n",
       " 'devil',\n",
       " 'diaries',\n",
       " 'diary',\n",
       " 'die',\n",
       " 'discworld',\n",
       " 'dog',\n",
       " 'don',\n",
       " 'dragon',\n",
       " 'dream',\n",
       " 'dreams',\n",
       " 'earth',\n",
       " 'empire',\n",
       " 'end',\n",
       " 'fall',\n",
       " 'fallen',\n",
       " 'family',\n",
       " 'fear',\n",
       " 'files',\n",
       " 'food',\n",
       " 'forever',\n",
       " 'forgotten',\n",
       " 'forgotten realms',\n",
       " 'game',\n",
       " 'garden',\n",
       " 'girl',\n",
       " 'girls',\n",
       " 'glass',\n",
       " 'god',\n",
       " 'gods',\n",
       " 'golden',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'grave',\n",
       " 'great',\n",
       " 'green',\n",
       " 'guide',\n",
       " 'hard',\n",
       " 'harry',\n",
       " 'harry bosch',\n",
       " 'harry potter',\n",
       " 'heart',\n",
       " 'heaven',\n",
       " 'hercule',\n",
       " 'hercule poirot',\n",
       " 'hidden',\n",
       " 'high',\n",
       " 'history',\n",
       " 'home',\n",
       " 'house',\n",
       " 'human',\n",
       " 'hunter',\n",
       " 'ice',\n",
       " 'immortals',\n",
       " 'inside',\n",
       " 'island',\n",
       " 'jack',\n",
       " 'jack reacher',\n",
       " 'john',\n",
       " 'journey',\n",
       " 'just',\n",
       " 'kay',\n",
       " 'kay scarpetta',\n",
       " 'key',\n",
       " 'king',\n",
       " 'kinsey',\n",
       " 'kinsey millhone',\n",
       " 'kiss',\n",
       " 'knight',\n",
       " 'know',\n",
       " 'lady',\n",
       " 'left',\n",
       " 'legacy',\n",
       " 'legend',\n",
       " 'life',\n",
       " 'light',\n",
       " 'like',\n",
       " 'little',\n",
       " 'lives',\n",
       " 'living',\n",
       " 'long',\n",
       " 'lord',\n",
       " 'lost',\n",
       " 'love',\n",
       " 'lucas',\n",
       " 'lucas davenport',\n",
       " 'magic',\n",
       " 'magician',\n",
       " 'man',\n",
       " 'memoir',\n",
       " 'men',\n",
       " 'mercy',\n",
       " 'midnight',\n",
       " 'millhone',\n",
       " 'mind',\n",
       " 'miss',\n",
       " 'moon',\n",
       " 'mr',\n",
       " 'murder',\n",
       " 'new',\n",
       " 'night',\n",
       " 'novel',\n",
       " 'novels',\n",
       " 'old',\n",
       " 'people',\n",
       " 'perfect',\n",
       " 'plum',\n",
       " 'poems',\n",
       " 'poirot',\n",
       " 'potter',\n",
       " 'power',\n",
       " 'pretty',\n",
       " 'prey',\n",
       " 'prey lucas',\n",
       " 'prince',\n",
       " 'princess',\n",
       " 'queen',\n",
       " 'reacher',\n",
       " 'realms',\n",
       " 'red',\n",
       " 'rising',\n",
       " 'river',\n",
       " 'road',\n",
       " 'rock',\n",
       " 'rose',\n",
       " 'saga',\n",
       " 'scarpetta',\n",
       " 'school',\n",
       " 'science',\n",
       " 'sea',\n",
       " 'second',\n",
       " 'secret',\n",
       " 'secrets',\n",
       " 'series',\n",
       " 'set',\n",
       " 'seven',\n",
       " 'shadow',\n",
       " 'shadows',\n",
       " 'short',\n",
       " 'sisters',\n",
       " 'small',\n",
       " 'snow',\n",
       " 'son',\n",
       " 'song',\n",
       " 'soul',\n",
       " 'star',\n",
       " 'stars',\n",
       " 'stephanie',\n",
       " 'stephanie plum',\n",
       " 'stone',\n",
       " 'stories',\n",
       " 'storm',\n",
       " 'story',\n",
       " 'strange',\n",
       " 'street',\n",
       " 'summer',\n",
       " 'sun',\n",
       " 'sword',\n",
       " 'tale',\n",
       " 'tales',\n",
       " 'tell',\n",
       " 'things',\n",
       " 'time',\n",
       " 'tree',\n",
       " 'trilogy',\n",
       " 'true',\n",
       " 'true story',\n",
       " 'truth',\n",
       " 'twilight',\n",
       " 'universe',\n",
       " 'vampire',\n",
       " 'vampire hunter',\n",
       " 'vampires',\n",
       " 'vol',\n",
       " 'volume',\n",
       " 'walking',\n",
       " 'walking dead',\n",
       " 'war',\n",
       " 'wars',\n",
       " 'water',\n",
       " 'way',\n",
       " 'wheel',\n",
       " 'white',\n",
       " 'wicked',\n",
       " 'wife',\n",
       " 'wild',\n",
       " 'winter',\n",
       " 'witch',\n",
       " 'woman',\n",
       " 'women',\n",
       " 'world',\n",
       " 'year',\n",
       " 'years']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets find vocabulary/features\n",
    "features = vect.get_feature_names()\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Similarity between Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_sim_titles = cosine_similarity(title_matrix, title_matrix)\n",
    "cosine_sim_titles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Me Talk Pretty One Day'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get books which are similar to a given title\n",
    "title_id = 100\n",
    "books_title['title'].iloc[title_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['day', 'pretty']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find out what features have been considered  by the vectorizer for a given title ?\n",
    "feature_array = np.squeeze(title_matrix[title_id].toarray()) #squeeze activity matrix into array\n",
    "idx = np.where(feature_array > 0)\n",
    "idx[0]\n",
    "[features[x] for x in idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 63, 179])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find index of feature\n",
    "idx[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.70710678, 0.70710678, 0.70710678, 0.70710678,\n",
       "       0.70710678, 0.70710678, 0.70710678, 0.70710678, 0.70710678,\n",
       "       0.70710678, 0.70710678, 0.70710678, 0.70710678, 0.70710678])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cosine similarity with other similar titles\n",
    "n = 15 #how many books to be recommended\n",
    "top_n_idx = np.flip(np.argsort(cosine_sim_titles[title_id,]), axis = 0)[0:n]\n",
    "top_n_sim_values = cosine_sim_titles[title_id, top_n_idx]\n",
    "top_n_sim_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100                                Me Talk Pretty One Day\n",
       "3729                                            Labor Day\n",
       "988                                 The Day of the Jackal\n",
       "836                             Every Day (Every Day, #1)\n",
       "2348    No Easy Day: The Firsthand Account of the Miss...\n",
       "3311                                          Pretty Baby\n",
       "6804                     Graduation Day (The Testing, #3)\n",
       "6886                                 Day Watch (Watch #2)\n",
       "5765                          The Given Day (Coughlin #1)\n",
       "783                                      For One More Day\n",
       "9210             Beyond Exile (Day by Day Armageddon,# 2)\n",
       "9703    The Pretty Committee Strikes Back (The Clique,...\n",
       "9637                                 Day 21 (The 100, #2)\n",
       "7330                                      Pretty in Plaid\n",
       "7707                            A Grown-Up Kind of Pretty\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find top n with values > 0\n",
    "top_n_idx = top_n_idx[top_n_sim_values > 0]\n",
    "#Matching books\n",
    "books_title['title'].iloc[top_n_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets wrap the above code in a function\n",
    "def return_sim_books(title_id, title_matrix, vectorizer, top_n = 10):\n",
    "    \n",
    "    # generate sim matrix\n",
    "    sim_matrix = cosine_similarity(title_matrix, title_matrix)\n",
    "    features = vectorizer.get_feature_names()\n",
    "\n",
    "    top_n_idx = np.flip(np.argsort(sim_matrix[title_id,]),axis=0)[0:top_n]\n",
    "    top_n_sim_values = sim_matrix[title_id, top_n_idx]\n",
    "    \n",
    "    # find top n with values > 0\n",
    "    top_n_idx = top_n_idx[top_n_sim_values > 0]\n",
    "    scores = top_n_sim_values[top_n_sim_values > 0]\n",
    "    \n",
    "    \n",
    "    # find features from the vectorized matrix\n",
    "    sim_books_idx = books_title['title'].iloc[top_n_idx].index\n",
    "    words = []\n",
    "    for book_idx in sim_books_idx:\n",
    "        try:\n",
    "            feature_array = np.squeeze(title_matrix[book_idx,].toarray())\n",
    "        except:\n",
    "            feature_array = np.squeeze(title_matrix[book_idx,])\n",
    "        idx = np.where(feature_array > 0)\n",
    "        words.append([\" , \".join([features[i] for i in idx[0]])])\n",
    "        \n",
    "    # collate results\n",
    "    res = pd.DataFrame({\"book_title\" : books_title['title'].iloc[title_id],\n",
    "           \"sim_books\": books_title['title'].iloc[top_n_idx].values,\"words\":words,\n",
    "           \"scores\":scores}, columns = [\"book_title\",\"sim_books\",\"scores\",\"words\"])\n",
    "    \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Kite Runner\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_title</th>\n",
       "      <th>sim_books</th>\n",
       "      <th>scores</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [book_title, sim_books, scores, words]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(analyzer='word',ngram_range=(1,2),stop_words='english', min_df = 0.001)\n",
    "vect.fit(books_title['title'])\n",
    "title_matrix = vect.transform(books_title['title'])\n",
    "print(books_title['title'][10])\n",
    "return_sim_books(10,title_matrix,vect,top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Using Tf-Idf Vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "tf = TfidfVectorizer(analyzer = 'word', ngram_range = (1,2), min_df = 0, stop_words = 'english')\n",
    "tfidf_matrix = tf.fit_transform(books_title['title'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = books_title['title']\n",
    "indices = pd.Series(books_title.index, index = books_title['title']) #converting all titles into a Series\n",
    "\n",
    "#Function that gets book recommendations based on the cosine similarity score of book titles\n",
    "def book_recommendations(title, n):\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key = lambda x:x[1], reverse = True)\n",
    "    sim_scores = sim_scores[1:n+1]\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    return titles.iloc[book_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Kite Runner\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8946                                        Once a Runner\n",
       "90                      The Maze Runner (Maze Runner, #1)\n",
       "375                      The Death Cure (Maze Runner, #3)\n",
       "945                    The Kill Order (Maze Runner, #0.5)\n",
       "258                   The Scorch Trials (Maze Runner, #2)\n",
       "6711    Ultramarathon Man: Confessions of an All-Night...\n",
       "0                 The Hunger Games (The Hunger Games, #1)\n",
       "1       Harry Potter and the Sorcerer's Stone (Harry P...\n",
       "2                                 Twilight (Twilight, #1)\n",
       "3                                   To Kill a Mockingbird\n",
       "4                                        The Great Gatsby\n",
       "5                                  The Fault in Our Stars\n",
       "6                                              The Hobbit\n",
       "7                                  The Catcher in the Rye\n",
       "8                   Angels & Demons  (Robert Langdon, #1)\n",
       "9                                     Pride and Prejudice\n",
       "11                              Divergent (Divergent, #1)\n",
       "12                                                   1984\n",
       "13                                            Animal Farm\n",
       "14                              The Diary of a Young Girl\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Recommend n books for a book having index 1\n",
    "book_index = 10\n",
    "n = 20\n",
    "\n",
    "print(books_title['title'][book_index])\n",
    "book_recommendations(books_title.title[book_index],n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
